# å¤šæ¨¡æ€è¿›è¡Œç–¾ç—…é¢„æµ‹

å¥½â€”â€”ä¸‹é¢ç»™ä½ ä¸€ä»½å®ç”¨ã€å¯æ“ä½œçš„å¤šæ¨¡æ€å»ºæ¨¡æŒ‡å—ï¼ˆä»æ•°æ®å‡†å¤‡åˆ°è®­ç»ƒã€è¯„ä¼°ã€ä¸Šçº¿ã€å¯è§£é‡Šæ€§ä¸åˆè§„æ€§ï¼‰ï¼Œå¹¶é™„å¸¦ä¸€ä¸ª**å¯è¿è¡Œçš„ PyTorch æ¨¡å‹éª¨æ¶**ï¼ˆæŠŠåŸºå› ç»„/è›‹ç™½ç»„å½“åšæ•°å€¼/å‘é‡ç‰¹å¾æˆ–åºåˆ—ç‰¹å¾ï¼Œä¸´åºŠæ–‡æœ¬ç”¨é¢„è®­ç»ƒ Transformerï¼‰ï¼Œå¯ç›´æ¥ç”¨ä½œèµ·ç‚¹å¹¶æŒ‰ä½ æ•°æ®ç»†åŒ–ã€‚è¯´æ˜é‡Œä¼šåŒ…å«å¸¸è§é™·é˜±å’Œå·¥ç¨‹å®è·µï¼ˆç¼ºå¤±æ¨¡æ€ã€æ ·æœ¬ä¸å‡è¡¡ã€æ‰¹æ¬¡æ•ˆåº”ã€æ¨¡å‹æ ¡å‡†ç­‰ï¼‰ã€‚
**æ³¨æ„ï¼ˆå®‰å…¨ä¸åˆè§„ï¼‰**ï¼šä»»ä½•ç”¨äºä¸´åºŠå†³ç­–çš„æ¨¡å‹éƒ½å¿…é¡»è¿›è¡Œä¸¥æ ¼çš„ä¸´åºŠéªŒè¯å’Œä¼¦ç†/åˆè§„å®¡æŸ¥ï¼›ä¸‹é¢ä»…ä¸ºå·¥ç¨‹/ç ”å‘æŒ‡å¯¼ï¼Œä¸æ„æˆåŒ»ç–—å»ºè®®ã€‚


# 1) é«˜å±‚æµç¨‹ï¼ˆç«¯åˆ°ç«¯æ¦‚è¦ï¼‰

1. æ•°æ®å¯¹é½ä¸æ ‡æ³¨ï¼šæŒ‰ç—…äºº ID å°†ä¸‰ç±»æ¨¡æ€ï¼ˆåŸºå› ç»„ã€è›‹ç™½ç»„ã€ä¸´åºŠæ–‡æœ¬ï¼‰å¯¹é½ï¼Œå®šä¹‰é¢„æµ‹ç›®æ ‡ï¼ˆbinary/multi-class/time-to-eventï¼‰ã€‚
2. é¢„å¤„ç†ï¼šæ¸…æ´—ã€ç¼ºå¤±å¤„ç†ã€æ‰¹æ¬¡/å¹³å°æ ¡æ­£ã€æ ‡å‡†åŒ–ã€tokenize æ–‡æœ¬ã€‚
3. æ¨¡æ€ç¼–ç å™¨ï¼šä¸ºæ¯ç§æ¨¡æ€è®¾è®¡æˆ–é€‰æ‹©åˆé€‚çš„ encoderï¼ˆä¾‹å¦‚ï¼šè¡¨å‹/omics ç”¨ MLP/1D-CNN/å˜æ¢å™¨ï¼Œæ–‡æœ¬ç”¨ ClinicalBERTï¼‰ã€‚
4. èåˆç­–ç•¥ï¼šé€‰æ‹© early / hybrid / late fusionï¼ˆè§ä¸‹æ–‡ï¼‰ã€‚åŠ ä¸Šå¤„ç†ç¼ºå¤±æ¨¡æ€çš„æœºåˆ¶ï¼ˆæ¨¡æ€æ©ç ã€imputationã€modality dropoutï¼‰ã€‚
5. æŸå¤±ä¸è®­ç»ƒï¼šåˆ†ç±»/å›å½’/ç”Ÿå­˜æŸå¤±ï¼Œå¯å¤šä»»åŠ¡ã€‚å¤„ç†ç±»ä¸å¹³è¡¡ï¼ˆåŠ æƒ/ focal loss /è¿‡é‡‡æ ·ï¼‰ã€‚
6. è¯„ä¼°ï¼šæ°å½“æŒ‡æ ‡ï¼ˆAUROCã€AUPRCã€sensitivity/ specificityã€calibrationã€CIã€å†³ç­–æ›²çº¿åˆ†æã€å¤–éƒ¨éªŒè¯ï¼‰ã€‚
7. å¯è§£é‡Šæ€§ï¼šSHAPã€integrated gradientsã€attention visualization + åŸºå› /è›‹ç™½çš„ç”Ÿç‰©å­¦è§£é‡Šã€‚
8. éƒ¨ç½²ä¸åˆè§„ï¼šå®¡è®¡æ—¥å¿—ã€å¯é‡å¤è®­ç»ƒç¯å¢ƒã€éšç§ä¿æŠ¤ï¼ˆå»æ ‡è¯†ã€è®¿é—®æ§åˆ¶ã€å·®åˆ†éšç§æˆ–è”é‚¦å­¦ä¹ ï¼‰ä¸ä¸´åºŠéªŒè¯æµç¨‹ã€‚



# 2) æ•°æ®å‡†å¤‡ç»†èŠ‚ï¼ˆå…³é”®è¦ç‚¹ï¼‰

* **å¯¹é½**ï¼šç¡®ä¿ä¸‰æ¨¡æ€æœ‰ç›¸åŒçš„ patient_idï¼›å¦‚æœæœ‰æ—¶é—´åºåˆ—ï¼ˆå¤šæ¬¡æµ‹é‡ï¼‰ï¼Œéœ€å†³å®šçª—å£/æ±‡æ€»ç­–ç•¥æˆ–ä½¿ç”¨æ—¶é—´æ¨¡å‹ï¼ˆRNN/Transformer/time-aware attentionï¼‰ã€‚
* **åŸºå› ç»„**ï¼š

  * å¦‚æœæ˜¯ variant åˆ—è¡¨/VCFï¼šå¯æŠŠæ¯ä¸ªæ ·æœ¬æ˜ å°„ä¸ºé¢„é€‰ä½ç‚¹çš„äºŒå€¼/é¢‘ç‡/æ³¨é‡Šå‘é‡ï¼Œæˆ–æå–åŠŸèƒ½æ³¨é‡Šï¼ˆSIFT/PolyPhen/åŸºå› ï¼‰ã€åŸºå› é›†å¯Œé›†åˆ†æ•°ç­‰ã€‚
  * å¦‚æœæ˜¯å…¨åŸºå› è¡¨è¾¾ï¼ˆRNA-seqï¼‰ï¼šåš TPM/FPKM -> log1p -> æ ‡å‡†åŒ–ï¼Œæˆ–é€‰å·®å¼‚è¡¨è¾¾/åŸºå› é›†ä½œä¸ºç‰¹å¾ã€‚
  * æ‰¹æ¬¡æ•ˆåº”ï¼šComBat / limma / removeBatchEffectã€‚
* **è›‹ç™½ç»„**ï¼ˆè›‹ç™½è¡¨è¾¾/è´¨è°±å¼ºåº¦ï¼‰ï¼šç¼ºå¤±å€¼å¤šï¼Œè€ƒè™‘ï¼šç¼ºå¤±æŒ‡ç¤ºç¬¦ + KNN/low-rank/feature-wise imputationï¼›log-transformï¼›æ‰¹æ¬¡æ ¡æ­£ã€‚
* **ä¸´åºŠæ–‡æœ¬**ï¼ˆç—…å†/å‡ºé™¢å°ç»“ï¼‰ï¼šå» PHI -> ç”¨ä¸´åºŠé¢„è®­ç»ƒæ¨¡å‹åˆ†è¯ï¼ˆBioClinicalBERTã€ClinicalBERTï¼Œæˆ–æ›´å¤§æ¨¡å‹å¦‚ PubMedBERTï¼‰ã€‚å¯æŠ½å–æ¦‚å¿µï¼ˆNegExã€cTAKESï¼‰ä½œä¸ºè¾…åŠ©ç‰¹å¾ã€‚
* **æ ·æœ¬ä¸å‡è¡¡**ï¼šç»Ÿè®¡é˜³æ€§/é˜´æ€§åˆ†å¸ƒï¼Œå‡†å¤‡ç­–ç•¥ï¼ˆé‡é‡‡æ ·ã€class weightsã€focal lossï¼‰ã€‚
* **æ•°æ®åˆ†å‰²**ï¼šæŒ‰ç—…äººåˆ†å‰² train/val/testï¼Œå°½é‡åšæ—¶é—´åˆ‡åˆ†ä¸å¤–éƒ¨éªŒè¯é›†ï¼›ä½¿ç”¨äº¤å‰éªŒè¯å¹¶ä¿è¯åˆ†å±‚ï¼ˆstratified K-foldï¼‰ã€‚



# 3) æ¨¡å‹ä¸èåˆç­–ç•¥ï¼ˆæƒè¡¡ä¸å»ºè®®ï¼‰

å¸¸è§æ–¹æ¡ˆä¸é€‚ç”¨åœºæ™¯ï¼š

A. **Late fusionï¼ˆç‹¬ç«‹ç¼–ç å™¨ + é¢„æµ‹å±‚é›†æˆï¼‰**

* å„æ¨¡æ€å•ç‹¬è®­ç»ƒ encoder è¾“å‡ºè¡¨å¾ï¼ˆvectorï¼‰ï¼Œå† concatenate åˆ°ä¸€ä¸ª MLP æˆ–åŠ æƒ ensemble è¿›è¡Œåˆ†ç±»ã€‚
* ä¼˜ç‚¹ï¼šæ¨¡å—åŒ–ã€æ˜“è§£é‡Šã€å¤„ç†ç¼ºå¤±æ¨¡æ€å®¹æ˜“ï¼ˆè‹¥æŸæ¨¡æ€ç¼ºå¤±å¯åªç”¨å…¶ä½™æ¨¡æ€ï¼‰ã€‚
* é€‚ç”¨ï¼šæ¨¡æ€å·®å¼‚å¤§ã€æ ·æœ¬é‡æœ‰é™æ—¶é¦–é€‰ã€‚

B. **Early / joint fusionï¼ˆåœ¨ encoder åæ—©æœŸæ‹¼æ¥ï¼Œç„¶åè”åˆ fine-tuneï¼‰**

* åœ¨ç¼–ç åæŠŠè¡¨ç¤ºæ‹¼æ¥å¹¶é€šè¿‡ Transformer / MLP è”åˆå­¦ä¹ äº¤å‰æ¨¡æ€äº¤äº’ã€‚
* ä¼˜ç‚¹ï¼šèƒ½å­¦ä¹ æ¨¡æ€é—´å¤æ‚ç›¸äº’ä½œç”¨ï¼Œæé«˜æ€§èƒ½ï¼ˆéœ€æ›´å¤šæ•°æ®/æ­£åˆ™åŒ–ï¼‰ã€‚

C. **Cross-attention / Multimodal Transformer**

* ä»¥æ–‡æœ¬ä½œä¸ºä¸»å¹²ï¼Œä½¿ç”¨ cross-attention å±‚å°† omics features æŠ•å½±ä¸º tokens å¹¶ä¸æ–‡æœ¬äº¤äº’ï¼ˆæˆ–ç›¸åï¼‰ã€‚
* é€‚ç”¨ï¼šå½“å¸Œæœ›æ¨¡å‹æ˜¾å¼å»ºæ¨¡â€œæ–‡æœ¬ä¸­æŸå¥å­ä¸æŸè›‹ç™½/åŸºå› â€çš„å…³è”æ—¶ã€‚å¤æ‚ä½†æ•ˆæœæ½œåŠ›é«˜ï¼ˆæ•°æ®é‡éœ€æ±‚é«˜ï¼‰ã€‚

D. **Mixture-of-experts / Gating**

* å­¦ä¹ ä¸€ä¸ª gating ç½‘ç»œå†³å®šæ¯ä¸ªæ¨¡æ€å¯¹æœ€ç»ˆé¢„æµ‹çš„è´¡çŒ®ï¼ˆå¯¹ç¼ºå¤±/å™ªå£°å¥å£®ï¼‰ã€‚

E. **Contrastive or multimodal pretraining**

* è‹¥æœ‰å¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®ï¼Œå¯å…ˆåšè·¨æ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼ˆSimCLR/CLIP é£æ ¼ï¼‰å†ä¸‹æ¸¸å¾®è°ƒï¼Œèƒ½æ˜¾è‘—æå‡å°‘æ ·æœ¬æ€§èƒ½ã€‚



# 4) å¤„ç†ç¼ºå¤±æ¨¡æ€ï¼ˆå®ç”¨æŠ€å·§ï¼‰

* åœ¨è®­ç»ƒä¸­åš **modality dropout**ï¼ˆéšæœºé®æ‰æŸæ¨¡æ€ï¼‰ä»¥è®­ç»ƒé²æ£’æ¨¡å‹ã€‚
* å¢åŠ  **æ¨¡æ€å­˜åœ¨æ ‡å¿—ä½**ï¼ˆone-hotï¼‰è¾“å…¥ç»™èåˆå±‚ã€‚
* å¯¹æ•°å€¼æ¨¡æ€åš imputation + åŠ ä¸Š imputed flagã€‚
* å¦‚æœç¼ºå¤±æ¨¡å¼ä¸æ˜¯éšæœºï¼ˆMNARï¼‰ï¼Œè€ƒè™‘ä¸“é—¨å»ºæ¨¡ç¼ºå¤±æœºåˆ¶æˆ–åˆ†å±‚å¤„ç†ã€‚



# 5) è¯„ä»·æŒ‡æ ‡ï¼ˆä¸´åºŠå¸¸ç”¨ï¼‰

* äºŒåˆ†ç±»ï¼šAUROC, AUPRCï¼ˆå½“é˜³æ€§ç¨€å°‘æ—¶ AUPRC æ›´é‡è¦ï¼‰ï¼Œsensitivity@specificity, F1, calibration (Brier score, reliability curve)ã€‚
* ç”Ÿå­˜é¢„æµ‹ï¼šC-indexã€time-dependent AUCã€‚
* æŠ¥å‘Šï¼š95% CIï¼ˆbootstrapï¼‰ï¼Œå†³ç­–æ›²çº¿åˆ†æï¼ˆnet benefitï¼‰ã€‚
* å¤–éƒ¨éªŒè¯ï¼šåœ¨ç‹¬ç«‹ cohort ä¸ŠéªŒè¯æ€§èƒ½å’Œæ¼‚ç§»ã€‚



# 6) å¯è§£é‡Šæ€§ä¸ç”Ÿç‰©å­¦éªŒè¯

* **å…¨å±€è§£é‡Š**ï¼šSHAP (tree/ deep explainer)ã€feature importance æ’åºã€‚
* **å±€éƒ¨è§£é‡Š**ï¼šIntegrated Gradientsã€LIMEã€‚
* **æ–‡æœ¬è§£é‡Š**ï¼šå¯è§†åŒ– attention scores æˆ– gradient-based highlight å…³é”®å¥å­ã€‚
* **ç”Ÿç‰©å­¦éªŒè¯**ï¼šæŸ¥è¯¢åŸºå› /è›‹ç™½æ˜¯å¦å‡ºç°åœ¨å·²çŸ¥é€šè·¯æˆ–æ–‡çŒ®ä¸­ï¼ˆKEGG/Reactome/PubMedï¼‰ã€‚



# 7) å·¥ç¨‹ç»†èŠ‚ä¸è®­ç»ƒæŠ€å·§

* **æ ‡å‡†åŒ–**ï¼šæ•°å€¼æ¨¡æ€ä½¿ç”¨è®­ç»ƒé›†å‡å€¼/æ–¹å·®ï¼›ä¿å­˜ scalerã€‚
* **æ‰¹æ¬¡æ•ˆåº”/å¹³å°å·®å¼‚**ï¼šåœ¨è®­ç»ƒ/éªŒè¯åˆ†å±‚åœ°æ§åˆ¶æ‰¹æ¬¡ï¼Œæˆ–ç”¨åŸŸè‡ªé€‚åº”æ–¹æ³•ã€‚
* **æ­£åˆ™åŒ–**ï¼šdropout, weight decay, early stoppingã€‚
* **ä¼˜åŒ–ä¸å­¦ä¹ ç‡**ï¼šAdamWï¼Œåˆ†ç±»å¤´ç”¨è¾ƒé«˜ lrï¼Œé¢„è®­ç»ƒæ–‡æœ¬ encoder ç”¨è¾ƒå° lrï¼ˆå‚æ•°åˆ†ç»„ï¼‰ã€‚
* **ç›‘æ§**ï¼šä½¿ç”¨ TensorBoard / Weights & Biases è·Ÿè¸ªæŒ‡æ ‡ã€æ¨¡å‹ç‰ˆæœ¬ã€‚
* **æ¨¡å‹é€‰æ‹©**ï¼šåœ¨ validation ä¸Šç”¨ AUROC/AUPRC åšé€‰å–ï¼Œå¹¶ä¿ç•™æœ€ä¼˜é˜ˆå€¼ã€‚
* **ç»Ÿè®¡æ˜¾è‘—æ€§**ï¼šå¯¹æ¯”åŸºçº¿æ¨¡å‹ï¼ˆä»…ä¸´åºŠå˜é‡/ä»…åŸºå› ç»„ï¼‰å¹¶åšç»Ÿè®¡æ£€éªŒï¼ˆDeLong test for AUROCï¼‰ã€‚



# 8) éšç§ã€æ³•è§„ã€éƒ¨ç½²

* å»è¯†åˆ«åŒ– PHIï¼›ä¿å­˜æœ€å°å¿…è¦æ•°æ®ã€‚
* è‹¥å¤šä¸­å¿ƒæ•°æ®æ•æ„Ÿï¼Œè€ƒè™‘ **è”é‚¦å­¦ä¹ ** æˆ–å·®åˆ†éšç§è®­ç»ƒï¼ˆDP-SGDï¼‰ã€‚
* éƒ¨ç½²ï¼šå°†æ¨¡å‹å®¹å™¨åŒ–ï¼ˆDockerï¼‰ï¼Œæš´éœ² REST APIï¼Œè®°å½•æ¨¡å‹ç‰ˆæœ¬ä¸è¾“å…¥ç‰¹å¾å“ˆå¸Œä»¥ä¾¿å®¡è®¡ã€‚
* ä¸´åºŠéƒ¨ç½²å‰éœ€ä¸´åºŠè¯•éªŒ/æ‰¹å‡†ä¸ä¼¦ç†å§”å‘˜ä¼šå®¡æ ¸ã€‚



# 9) æ¨èçš„èµ·æ­¥æ¨¡å‹æ¶æ„ï¼ˆå®ç”¨ PyTorch skeletonï¼‰

ä¸‹é¢ç»™å‡ºä¸€ä¸ª**å¯è¿è¡Œçš„ PyTorch skeleton**ï¼š

* æ–‡æœ¬ç”¨ HuggingFace Transformerï¼ˆéœ€å®‰è£… `transformers`ï¼‰ã€‚
* Omicsï¼ˆåŸºå› /è›‹ç™½ï¼‰å½“ä½œæ•°å€¼å‘é‡ç”¨ç®€å• MLP ç¼–ç ã€‚
* èåˆé‡‡ç”¨ early fusionï¼ˆconcatenate â†’ MLPï¼‰ã€‚
* åŒ…å« modality dropoutã€class weightã€è®­ç»ƒä¸è¯„ä¼°å‡½æ•°ã€‚

> ä¸‹é¢ä»£ç ä¸ºéª¨æ¶ï¼Œéœ€æ ¹æ®ä½ æ•°æ® shapeï¼ˆomics feature æ•°ï¼‰è°ƒæ•´ `OMICS_DIM` å’Œ batch dataset åˆ¶ä½œã€‚

```python
# multimodal_model.py
import os
import math
import random
from typing import Dict
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoModel, AutoTokenizer
from sklearn.metrics import roc_auc_score, average_precision_score

# -------------------------
# Config / Hyperparams (adjust)
# -------------------------
TEXT_MODEL_NAME = "emilyalsentzer/Bio_ClinicalBERT"  # or "bert-base-uncased"
OMICS_DIM = 1024   # number of numeric omics features per sample (adjust)
HIDDEN_DIM = 256
BATCH_SIZE = 16
LR = 2e-5
EPOCHS = 10
MODALITY_DROPOUT_P = 0.2  # during training randomly drop a modality
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# -------------------------
# Dataset skeleton (implement loading + preprocessing)
# -------------------------
class MultiModalDataset(Dataset):
    """
    Each item should be a dict:
      {
        "patient_id": ...,
        "text": "clinical note ...",
        "omics": np.array([...]) or torch.tensor,
        "label": 0/1
      }
    """
    def __init__(self, records):
        self.recs = records
        self.tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL_NAME)
    def __len__(self): return len(self.recs)
    def __getitem__(self, idx):
        r = self.recs[idx]
        text = r.get("text","")
        toks = self.tokenizer(text, truncation=True, padding='max_length', max_length=256, return_tensors="pt")
        omics = torch.tensor(r.get("omics", [0.0]*OMICS_DIM), dtype=torch.float32)
        label = torch.tensor(r["label"], dtype=torch.float32)
        return {"input_ids": toks["input_ids"].squeeze(0),
                "attention_mask": toks["attention_mask"].squeeze(0),
                "omics": omics,
                "label": label,
                "patient_id": r.get("patient_id")}

# -------------------------
# Model
# -------------------------
class TextEncoder(nn.Module):
    def __init__(self, model_name=TEXT_MODEL_NAME, out_dim=HIDDEN_DIM):
        super().__init__()
        self.backbone = AutoModel.from_pretrained(model_name)
        hidden_size = self.backbone.config.hidden_size
        self.project = nn.Linear(hidden_size, out_dim)
    def forward(self, input_ids, attention_mask):
        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)[0]  # last_hidden_state
        pooled = out[:,0,:]  # [CLS]
        return self.project(pooled)

class OmicsEncoder(nn.Module):
    def __init__(self, in_dim=OMICS_DIM, out_dim=HIDDEN_DIM):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, in_dim//2),
            nn.ReLU(),
            nn.BatchNorm1d(in_dim//2),
            nn.Linear(in_dim//2, out_dim),
            nn.ReLU()
        )
    def forward(self, x):
        return self.net(x)

class MultiModalClassifier(nn.Module):
    def __init__(self, text_dim=HIDDEN_DIM, omics_dim=HIDDEN_DIM, hidden=128):
        super().__init__()
        self.text_enc = TextEncoder(out_dim=text_dim)
        self.omics_enc = OmicsEncoder(in_dim=OMICS_DIM, out_dim=omics_dim)
        self.fusion = nn.Sequential(
            nn.Linear(text_dim + omics_dim + 2, hidden), # +2 for modality presence flags
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden, 1)
        )
    def forward(self, input_ids, attention_mask, omics, modality_mask=None):
        """
        modality_mask: dict {"text": bool, "omics": bool} indicating presence
        """
        text_feat = self.text_enc(input_ids, attention_mask) if modality_mask.get("text", True) else torch.zeros((omics.size(0), HIDDEN_DIM), device=omics.device)
        omics_feat = self.omics_enc(omics) if modality_mask.get("omics", True) else torch.zeros((omics.size(0), HIDDEN_DIM), device=omics.device)
        # modality presence flags
        text_pres = (1.0 if modality_mask.get("text", True) else 0.0)
        omics_pres = (1.0 if modality_mask.get("omics", True) else 0.0)
        flags = torch.tensor([text_pres, omics_pres], device=omics.device).unsqueeze(0).repeat(omics.size(0),1)
        h = torch.cat([text_feat, omics_feat, flags], dim=1)
        logits = self.fusion(h).squeeze(-1)
        return logits

# -------------------------
# Training & evaluation helpers
# -------------------------
def train_epoch(model, dataloader, opt, epoch):
    model.train()
    total_loss = 0.0
    criterion = nn.BCEWithLogitsLoss()  # could add pos_weight for imbalance
    for batch in dataloader:
        input_ids = batch["input_ids"].to(DEVICE)
        attention_mask = batch["attention_mask"].to(DEVICE)
        omics = batch["omics"].to(DEVICE)
        labels = batch["label"].to(DEVICE)
        # random modality dropout
        modality_mask = {"text": True, "omics": True}
        if random.random() < MODALITY_DROPOUT_P:
            modality_mask["text"] = False
        if random.random() < MODALITY_DROPOUT_P:
            modality_mask["omics"] = False
        logits = model(input_ids, attention_mask, omics, modality_mask)
        loss = criterion(logits, labels)
        opt.zero_grad()
        loss.backward()
        opt.step()
        total_loss += loss.item() * labels.size(0)
    return total_loss / len(dataloader.dataset)

def evaluate(model, dataloader):
    model.eval()
    ys, ps = [], []
    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch["input_ids"].to(DEVICE)
            attention_mask = batch["attention_mask"].to(DEVICE)
            omics = batch["omics"].to(DEVICE)
            labels = batch["label"].cpu().numpy()
            modality_mask = {"text": True, "omics": True}  # use full modalities during eval
            logits = model(input_ids, attention_mask, omics, modality_mask)
            probs = torch.sigmoid(logits).cpu().numpy()
            ys.extend(labels.tolist())
            ps.extend(probs.tolist())
    auc = roc_auc_score(ys, ps) if len(set(ys))>1 else float("nan")
    aupr = average_precision_score(ys, ps) if len(set(ys))>1 else float("nan")
    return {"auc": auc, "aupr": aupr}

# -------------------------
# Example train loop (pseudo)
# -------------------------
def run_training(train_records, val_records):
    train_ds = MultiModalDataset(train_records)
    val_ds = MultiModalDataset(val_records)
    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)
    model = MultiModalClassifier().to(DEVICE)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
    best_auc = -1
    for epoch in range(EPOCHS):
        tr_loss = train_epoch(model, train_dl, optimizer, epoch)
        metrics = evaluate(model, val_dl)
        print(f"Epoch {epoch}: loss {tr_loss:.4f} val_auc {metrics['auc']:.4f} val_aupr {metrics['aupr']:.4f}")
        if metrics["auc"] > best_auc:
            best_auc = metrics["auc"]
            torch.save(model.state_dict(), "best_multimodal.pt")
    return model

# -------------------------
# Note: you'll need to prepare `train_records` and `val_records` lists of dicts as dataset input
# -------------------------
```

è¿™æ®µéª¨æ¶åŒ…å«å…³é”®å·¥ç¨‹å…ƒç´ ï¼šæ–‡æœ¬ encoderï¼ˆå¯ç”¨ pretrained transformerï¼‰ï¼Œomics encoderï¼ˆMLPï¼‰ï¼Œæ‹¼æ¥èåˆï¼Œmodality dropoutã€‚**åœ¨çœŸå®å·¥ç¨‹é‡Œä½ åº”å½“**ï¼š

* è°ƒæ•´ tokenizer/truncationã€batch sizeï¼ˆæ˜¾å­˜å—é™æ—¶å‡å°ï¼‰ï¼Œå¹¶æŠŠ Omics ç‰¹å¾ç»´åº¦ä¸çœŸå®æ•°æ®å¯¹é½ï¼›
* åŠ å…¥ class weightsã€early stoppingã€LR è°ƒåº¦å™¨ã€æ··åˆç²¾åº¦è®­ç»ƒï¼ˆ`torch.cuda.amp`ï¼‰ä»¥åŠ é€Ÿï¼›
* åœ¨éªŒè¯/æµ‹è¯•ä¸­ç¦ç”¨ modality dropout å¹¶ä½¿ç”¨å®Œæ•´æ•°æ®ï¼›åœ¨è®­ç»ƒæ—¶ç”¨éšæœºé®ç›–æé«˜é²æ£’æ€§ã€‚



# 10) è¿›é˜¶ï¼šè‹¥ä½ çš„æ•°æ®é‡è¾ƒå¤§æˆ–æ¨¡æ€å¤æ‚

* ä½¿ç”¨ **cross-attention** å±‚æˆ– multimodal transformerï¼ˆæ¯”å¦‚å°† omics ç‰¹å¾è§†ä¸º tokensï¼‰æ¥æ•æ‰ç»†ç²’åº¦äº¤äº’ã€‚
* é‡‡ç”¨ **contrastive pretraining**ï¼šæŠŠæ–‡æœ¬ä¸ omics å¯¹ä½œä¸ºæ­£æ ·æœ¬ï¼Œéå¯¹åº”ç—…äººä½œä¸ºè´Ÿæ ·æœ¬è®­ç»ƒå…±äº«è¡¨å¾ï¼ˆCLIP é£æ ¼ï¼‰ã€‚
* å¦‚æœæœ‰ time-seriesï¼ˆå¤šæ—¶é—´ç‚¹ï¼‰ï¼Œç”¨ time-aware transformer / temporal convolution ç½‘ç»œã€‚



# 11) å®éªŒè®¾è®¡ä¸æŠ¥å‘Šå»ºè®®

* è®°å½•å¹¶æŠ¥å‘Šï¼šè®­ç»ƒ/éªŒè¯/æµ‹è¯•çš„ cohort æ¥æºã€æ—¶é—´èŒƒå›´ã€è®¾å¤‡/æµ‹åºå¹³å°ã€é¢„å¤„ç†æµæ°´çº¿ã€è¶…å‚ã€éšæœºç§å­ã€ç‰ˆæœ¬åŒ–æ¨¡å‹ã€‚
* åš**å­ç¾¤æ€§èƒ½åˆ†æ**ï¼ˆæŒ‰å¹´é¾„ã€æ€§åˆ«ã€ç§æ—ã€æ‰¹æ¬¡ï¼‰æ£€æµ‹åå·®ã€‚
* æŠ¥å‘Šæ¨¡å‹ä¸ç¡®å®šæ€§ä¸æ ¡å‡†ï¼ˆç½®ä¿¡åŒºé—´ã€ç½®ä¿¡åˆ†æ•°ï¼‰ã€‚



# 12) æœ€åç»™ä½ ä¸€ç»„å®ç”¨ checklistï¼ˆåšç ”å‘æ—¶è·Ÿç€åšï¼‰

* [ ] patient_id å¯¹é½ä¸å»é‡å®Œæˆ
* [ ] æ‰€æœ‰æ¨¡æ€ç¼ºå¤±ç‡ç»Ÿè®¡ã€åˆ†å¸ƒå¯è§†åŒ–
* [ ] æ‰¹æ¬¡æ•ˆåº”æ£€æµ‹ä¸æ ¡æ­£ç­–ç•¥å°±ç»ª
* [ ] train/val/test ä¸¥æ ¼åˆ†å‰²ï¼ˆå¤–éƒ¨éªŒè¯é›†ï¼‰
* [ ] baseline æ¨¡å‹ï¼ˆä»…ä¸´åºŠï¼Œä»… omicsï¼‰å¯¹æ¯”
* [ ] æ¨¡å‹ç¨³å¥æ€§éªŒè¯ï¼ˆå™ªå£°, ç¼ºæ¨¡æ€ï¼‰
* [ ] å¯è§£é‡Šæ€§åˆ†æï¼ˆgene/protein å¯Œé›†ã€æ–‡æœ¬ç‰‡æ®µï¼‰
* [ ] æ³•å¾‹/ä¼¦ç†/éšç§å®¡æŸ¥ï¼ˆPHIã€åˆè§„ï¼‰
* [ ] å®Œæ•´çš„è®­ç»ƒå¯å¤ç°è„šæœ¬ä¸å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆ



å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ï¼š

* åŸºäºä½ ç°æœ‰æ•°æ®çš„**æ›´å…·ä½“å»ºè®®**ï¼ˆä¾‹å¦‚ï¼šå¦‚æœä½ æŠŠåŸºå› ç»„ç»™æˆ‘æè¿°ä¸ºâ€œVCF with 1000 candidate SNPsâ€ æˆ–è€…â€œåŸºå› è¡¨è¾¾çŸ©é˜µ 20k genes Ã— N samplesâ€ï¼Œæˆ‘ä¼šæ ¹æ®å½¢æ€ç»™å‡ºæ›´ç²¾ç¡®çš„ encoder è®¾è®¡ä¸è¶…å‚æ•°ï¼‰ï¼›
* æˆ–è€…æŠŠä¸Šé¢çš„ PyTorch éª¨æ¶ **æ”¹æˆæ”¯æŒ cross-attention çš„ç‰ˆæœ¬**ï¼›
* ä¹Ÿå¯ä»¥å¸®ä½ å†™æ•°æ®åŠ è½½å™¨ç¤ºä¾‹ï¼ˆä» VCFã€è¡¨æ ¼æˆ–è´¨è°±è¾“å‡ºè½¬æ¢ä¸ºæ¨¡å‹å¯ç”¨å½¢å¼ï¼‰ï¼Œå¹¶æ¼”ç¤ºå¦‚ä½•åšåˆ†å±‚ splitã€class weight è®¡ç®—å’Œæ¨¡å‹è¯„ä¼°è„šæœ¬ã€‚

ä½ æƒ³å…ˆè¦å“ªä¸€éƒ¨åˆ†çš„å…·ä½“å®ç°ï¼Ÿï¼ˆæˆ‘ä¼šç›´æ¥ç»™å‡ºä»£ç /æ­¥éª¤ï¼Œä¸å†é—®åˆ«çš„é—®é¢˜ã€‚ï¼‰

---

# å·å´ç—…å¤šæ¨¡æ€

è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„è¯¾é¢˜æ–¹å‘ã€‚å·å´ç—…ï¼ˆKawasaki Disease, KDï¼‰çš„ä¸´åºŠè¡¨ç°å’Œå¹¶å‘ç—‡ï¼ˆå°¤å…¶æ˜¯å† çŠ¶åŠ¨è„‰ç—…å˜, CALï¼‰å…·æœ‰å¤šæ¨¡æ€ç‰¹å¾ã€‚è¦æ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œ**æ•°æ®å‡†å¤‡æ˜¯æˆåŠŸçš„å…³é”®**ã€‚

é’ˆå¯¹å·å´ç—…ä¸´åºŠæ•°æ®çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ‚¨éœ€è¦ä»ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦æ–¹é¢è¿›è¡Œç³»ç»Ÿæ€§çš„å‡†å¤‡ï¼š

## ğŸ’¡ ä¸€ã€ æ•°æ®çš„é‡‡é›†ä¸æ•´åˆ (Data Collection and Integration)

å¤šæ¨¡æ€æ¨¡å‹éœ€è¦æ•´åˆ**è‡³å°‘ä¸¤ç§ä¸åŒç±»å‹**çš„æ•°æ®ã€‚å¯¹äºå·å´ç—…ï¼Œæ ¸å¿ƒæ¨¡æ€é€šå¸¸åŒ…æ‹¬ï¼š

### 1\. ä¸´åºŠ/è¡¨æ ¼æ•°æ®ï¼ˆTabular/EHR Dataï¼‰

  * **åŸºç¡€ä¿¡æ¯ï¼š** å¹´é¾„ã€æ€§åˆ«ã€å‘ç—…è‡³æ²»ç–—æ—¶é—´ï¼ˆIVIGå‰å‘çƒ­æ—¶é•¿ï¼‰ã€ä½“æ¸©æ›²çº¿ç­‰ã€‚
  * **ä¸´åºŠè¡¨ç°ï¼š** 5é¡¹ä¸»è¦ä¸´åºŠç‰¹å¾ï¼ˆç»“è†œå……è¡€ã€å£å”‡æ”¹å˜ã€çš®ç–¹ã€å››è‚¢æœ«ç«¯æ”¹å˜ã€æ·‹å·´ç»“è‚¿å¤§ï¼‰çš„**æœ‰æ— ã€ç¨‹åº¦å’ŒæŒç»­æ—¶é—´**ã€‚
  * **å®éªŒå®¤æŒ‡æ ‡ï¼š**
      * **æ€¥æ€§æœŸç‚ç—‡æŒ‡æ ‡ï¼š** $CRP$ï¼ˆCååº”è›‹ç™½ï¼‰ã€$ESR$ï¼ˆçº¢ç»†èƒæ²‰é™ç‡ï¼‰ã€$WBC$ï¼ˆç™½ç»†èƒï¼‰ã€ä¸­æ€§ç²’ç»†èƒæ¯”ä¾‹ã€è¡€å°æ¿è®¡æ•°ï¼ˆé«˜å³°æœŸï¼‰ã€è¡€æ¸…é“è›‹ç™½ã€ç™½è›‹ç™½ã€$ALT$ï¼ˆè°·ä¸™è½¬æ°¨é…¶ï¼‰ç­‰ã€‚
      * **å…¶ä»–ï¼š** è¡€çº¢è›‹ç™½ã€å°¿å¸¸è§„ç™½ç»†èƒç­‰ã€‚
  * **æ²»ç–—ä¿¡æ¯ï¼š** $IVIG$ï¼ˆé™è„‰æ³¨å°„å…ç–«çƒè›‹ç™½ï¼‰å‰‚é‡ã€ç»™è¯æ—¶é—´ã€æ˜¯å¦å¯¹$IVIG$æ— åº”ç­”ã€æ˜¯å¦ä½¿ç”¨äº†æ¿€ç´ æˆ–å…¶ä»–å…ç–«æŠ‘åˆ¶å‰‚ã€‚
  * **ç»“å±€æ ‡ç­¾ï¼ˆæ¨¡å‹ç›®æ ‡ï¼‰ï¼š** æ˜¯å¦å‘ç”Ÿ$CAL$ï¼ˆå† çŠ¶åŠ¨è„‰ç—…å˜ï¼‰ã€$CAL$çš„ä¸¥é‡ç¨‹åº¦ï¼ˆæŒ‰$Z$å€¼æˆ–ç»å¯¹å†…å¾„åˆ†çº§ï¼šæ‰©å¼ ã€å°å‹$CAA$ã€ä¸­å‹$CAA$ã€å·¨å‹$CAA$ï¼‰ã€æ˜¯å¦éœ€è¦äºŒæ¬¡æ²»ç–—ç­‰ã€‚

### 2\. å½±åƒæ•°æ® (Imaging Data)

  * **è¶…å£°å¿ƒåŠ¨å›¾å›¾åƒ/è§†é¢‘ï¼š** å† çŠ¶åŠ¨è„‰çš„**åŸå§‹å›¾åƒã€è§†é¢‘ç‰‡æ®µ**ï¼Œä»¥åŠå¯¹å·¦å† çŠ¶åŠ¨è„‰å‰é™æ”¯ï¼ˆ$LAD$ï¼‰ã€å³å† çŠ¶åŠ¨è„‰ï¼ˆ$RCA$ï¼‰ç­‰å…³é”®éƒ¨ä½çš„**æµ‹é‡ç»“æœ**ï¼ˆå¦‚$Z$å€¼ã€$mm$å†…å¾„ï¼‰ã€‚
  * **å¿ƒç”µå›¾/åŠ¨æ€å¿ƒç”µå›¾ï¼ˆECG/Holterï¼‰ï¼š** åŸå§‹æ³¢å½¢æ•°æ®ã€‚
  * **å…¶ä»–å½±åƒï¼ˆè‹¥æœ‰ï¼‰ï¼š** å¿ƒè„$CT$/ç£å…±æŒ¯ï¼ˆ$MRI$ï¼‰å›¾åƒã€‚

### 3\. æ–‡æœ¬æ•°æ® (Textual Data)

  * **ç—…å†æ–‡æœ¬ï¼š** å…¥é™¢è®°å½•ã€å‡ºé™¢å°ç»“ã€ä¸»è¯‰ã€ä½“æ ¼æ£€æŸ¥è®°å½•ã€è¶…å£°å¿ƒåŠ¨å›¾æŠ¥å‘Šçš„**æè¿°æ€§æ–‡å­—**ã€‚
  * **ç›®çš„ï¼š** æå–éç»“æ„åŒ–ä¿¡æ¯ï¼Œæˆ–ç”¨äº**é¢„è®­ç»ƒ**åŒ»å­¦è¯­è¨€æ¨¡å‹ã€‚


## ğŸ”¬ äºŒã€ æ•°æ®æ¸…æ´—ä¸æ ‡å‡†åŒ– (Cleaning and Standardization)

è¿™æ˜¯å¤šæ¨¡æ€æ•°æ®å‡†å¤‡ä¸­**æœ€è€—æ—¶ä¹Ÿæœ€å…³é”®**çš„ä¸€æ­¥ã€‚

### 1\. ä¸´åºŠæ•°æ® (Tabular Data)

  * **ç¼ºå¤±å€¼å¤„ç†ï¼š** è¯†åˆ«å’Œå¡«å……ç¼ºå¤±å€¼ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å¹³å‡å€¼ã€ä¸­ä½æ•°æˆ–æ›´å¤æ‚çš„æ’å€¼æ³•ï¼‰ã€‚
  * **å¼‚å¸¸å€¼æ£€æµ‹ï¼š** è¯†åˆ«å¹¶å¤„ç†ä¸åˆé€»è¾‘çš„æ•°å€¼ï¼ˆä¾‹å¦‚ï¼Œè¶…å‡ºç”Ÿç†èŒƒå›´çš„$CRP$å€¼ï¼‰ã€‚
  * **æ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼š** å°†è¿ç»­æ€§æ•°å€¼ç‰¹å¾è¿›è¡Œç¼©æ”¾ï¼ˆå¦‚$Min-Max$å½’ä¸€åŒ–æˆ–$Z-score$æ ‡å‡†åŒ–ï¼‰ï¼Œä»¥æ¶ˆé™¤é‡çº²å·®å¼‚å¯¹æ¨¡å‹çš„å½±å“ã€‚
  * **ç‰¹å¾å·¥ç¨‹ï¼š** æ ¹æ®æŒ‡å—å’Œä¸´åºŠç»éªŒï¼Œåˆ›å»ºæ–°çš„æœ‰æ„ä¹‰çš„ç‰¹å¾ï¼Œå¦‚ï¼š
      * è®¡ç®—$Z$å€¼ä¸å† çŠ¶åŠ¨è„‰å†…å¾„çš„å…³ç³»ã€‚
      * å°†å‘çƒ­æ—¶é•¿ã€å¹´é¾„ç­‰è½¬åŒ–ä¸º**åˆ†ç®±**ç‰¹å¾ã€‚
      * å°†ç‚ç—‡æŒ‡æ ‡è¿›è¡Œ**æ¯”ç‡**è®¡ç®—ï¼ˆå¦‚$CRP/ESR$ï¼‰ã€‚

### 2\. å½±åƒæ•°æ® (Imaging Data)

  * **ç»Ÿä¸€æ ¼å¼ï¼š** å°†æ‰€æœ‰å›¾åƒæˆ–è§†é¢‘æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯æ¥å—çš„ç»Ÿä¸€æ ¼å¼ï¼ˆå¦‚$DICOM$è½¬$PNG$ï¼‰ã€‚
  * **é¢„å¤„ç†ï¼š**
      * **å›¾åƒè£å‰ª/ç¼©æ”¾ï¼š** ç¡®ä¿å›¾åƒå°ºå¯¸ä¸€è‡´ï¼Œçªå‡ºæ˜¾ç¤ºå† çŠ¶åŠ¨è„‰ç­‰æ„Ÿå…´è¶£åŒºåŸŸï¼ˆ$ROI$ï¼‰ã€‚
      * **å›¾åƒå¢å¼ºï¼š** æé«˜å¯¹æ¯”åº¦ã€é™å™ªç­‰ï¼Œæ”¹å–„å›¾åƒè´¨é‡ã€‚
  * **æ ‡æ³¨ï¼š** **é«˜è´¨é‡çš„æ ‡æ³¨**æ˜¯æ¨¡å‹è®­ç»ƒçš„åŸºç¡€ã€‚éœ€è¦ç”±ç»éªŒä¸°å¯Œçš„å„¿ç§‘æˆ–å¿ƒè¡€ç®¡åŒ»ç”Ÿå¯¹å…³é”®ç»“æ„ï¼ˆå¦‚å† çŠ¶åŠ¨è„‰ç—…å˜ä½ç½®ã€$CAA$çš„è¾¹ç•Œï¼‰è¿›è¡Œæ ‡æ³¨ã€‚

### 3\. æ–‡æœ¬æ•°æ® (Textual Data)

  * **è„±æ•å¤„ç†ï¼š** ç§»é™¤æ‚£è€…éšç§ä¿¡æ¯ï¼ˆ$PHI$ï¼‰ã€‚
  * **ç»“æ„åŒ–/ä¿¡æ¯æŠ½å–ï¼š** ä½¿ç”¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆ$NLP$ï¼‰æŠ€æœ¯ä»æè¿°æ€§æŠ¥å‘Šä¸­æŠ½å–å…³é”®ä¿¡æ¯ï¼Œå¦‚ï¼šå°†â€œå† çŠ¶åŠ¨è„‰æ˜æ˜¾æ‰©å¼ ï¼Œç›´å¾„$5.2mm$â€ç»“æ„åŒ–ä¸ºâ€œ$RCA$ç›´å¾„ï¼š$5.2mm$â€ã€‚
  * **åˆ†è¯ä¸åµŒå…¥ï¼š** å¯¹ä¸­æ–‡åŒ»å­¦æ–‡æœ¬è¿›è¡Œå‡†ç¡®åˆ†è¯ï¼Œå¹¶ä½¿ç”¨åŒ»å­¦é¢†åŸŸé¢„è®­ç»ƒçš„è¯å‘é‡æ¨¡å‹ï¼ˆå¦‚$BERT$æˆ–$GPT$å˜ä½“ï¼‰è¿›è¡Œç¼–ç ã€‚


## ğŸ§± ä¸‰ã€ å¤šæ¨¡æ€å¯¹é½ä¸èåˆ (Alignment and Fusion)

è¿™æ˜¯å¤šæ¨¡æ€æ¨¡å‹çš„**æ ¸å¿ƒæŠ€æœ¯æŒ‘æˆ˜**ã€‚

### 1\. æ—¶é—´è½´å¯¹é½ (Temporal Alignment)

å·å´ç—…çš„ä¸´åºŠæ•°æ®å…·æœ‰**æ—¶é—´ä¾èµ–æ€§**ã€‚

  * **é—®é¢˜ï¼š** ä¸åŒçš„æ£€æŸ¥ï¼ˆè¡€å¸¸è§„ã€è¶…å£°å¿ƒåŠ¨å›¾ï¼‰å¯èƒ½å‘ç”Ÿåœ¨ä¸åŒçš„ç—…ç¨‹é˜¶æ®µï¼ˆæ€¥æ€§æœŸã€äºšæ€¥æ€§æœŸã€æ¢å¤æœŸï¼‰ã€‚
  * **å‡†å¤‡ï¼š** å»ºç«‹**ç»Ÿä¸€çš„æ—¶é—´æˆ³**ã€‚ä¾‹å¦‚ï¼Œä»¥**å‘ç—…æ—¥**æˆ–**é¦–æ¬¡$IVIG$æ²»ç–—æ—¥**ä¸º$T_0$ï¼Œå°†æ‰€æœ‰æ•°æ®ç‚¹ï¼ˆå¦‚$CRP$ã€$WBC$ã€å† è„‰$Z$å€¼ï¼‰**å¯¹é½**åˆ°ç‰¹å®šçš„æ—¶é—´çª—å£ï¼ˆå¦‚$T_0$ã€$T_0+1$å¤©ã€$T_0+7$å¤©ï¼‰ã€‚å¯¹äºé¢„æµ‹$IVIG$æ— åº”ç­”çš„æ¨¡å‹ï¼Œéœ€è¦ç¡®ä¿åªä½¿ç”¨**æ²»ç–—å‰**çš„æ•°æ®ã€‚

### 2\. æ¨¡æ€é—´å¯¹é½ (Inter-Modal Alignment)

  * **é€»è¾‘å…³è”ï¼š** ç¡®ä¿ä¸åŒæ¨¡æ€çš„æ•°æ®å±äº**åŒä¸€ä¸ªç—…ä¾‹**ã€**åŒä¸€ä¸ªæ—¶é—´æ®µ**ã€å¹¶æè¿°**åŒä¸€ä¸ªä¸´åºŠç°è±¡**ã€‚ä¾‹å¦‚ï¼Œè¶…å£°å¿ƒåŠ¨å›¾æŠ¥å‘Šä¸­çš„$CAA$æè¿°åº”ä¸å¯¹åº”çš„$Z$å€¼å’ŒåŸå§‹å›¾åƒç›¸åŒ¹é…ã€‚

### 3\. æ•°æ®é›†åˆ’åˆ†

  * å°†å‡†å¤‡å¥½çš„æ•°æ®é›†åˆ’åˆ†ä¸º**è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†**ã€‚
  * **æ³¨æ„ï¼š** ç¡®ä¿å„æ•°æ®é›†ä¸­çš„**ç›®æ ‡æ ‡ç­¾ï¼ˆå¦‚$CAL$å‘ç”Ÿç‡ï¼‰åˆ†å¸ƒä¸€è‡´**ï¼Œä»¥é¿å…æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°ä¸ä½³ã€‚

**æ€»ç»“ä¸€ä¸ªæ¸…å•ï¼Œä»¥æŒ‡å¯¼æ‚¨çš„å·¥ä½œï¼š**

| é˜¶æ®µ | ä»»åŠ¡é‡ç‚¹ | å…·ä½“è¡ŒåŠ¨/å…³é”®æŒ‡æ ‡ |
| :--- | :--- | :--- |
| **é‡‡é›†ä¸å®šä¹‰** | **æ˜ç¡®æ¨¡æ€å’Œæ ‡ç­¾** | ç¡®å®šï¼šè¡¨æ ¼æ•°æ®ï¼ˆå®éªŒå®¤æŒ‡æ ‡ã€ä¸´åºŠä½“å¾ï¼‰ã€å½±åƒæ•°æ®ï¼ˆè¶…å£°$Z$å€¼/å›¾åƒï¼‰ã€ç›®æ ‡ï¼ˆ$CAL$åˆ†çº§ï¼‰ã€‚ |
| **æ¸…æ´—ä¸é¢„å¤„ç†** | **æ ‡å‡†åŒ–æ•°æ®è´¨é‡** | **è¡¨æ ¼ï¼š** ç¼ºå¤±å€¼å¡«å……ã€å¼‚å¸¸å€¼å¤„ç†ã€ç‰¹å¾å½’ä¸€åŒ–ã€‚<br>**å½±åƒï¼š** ç»Ÿä¸€å°ºå¯¸ã€å»å™ªã€é«˜è´¨é‡æ ‡æ³¨$CAL$åŒºåŸŸã€‚ |
| **å¯¹é½ä¸èåˆ** | **å»ºç«‹æ—¶é—´ä¸é€»è¾‘å…³è”** | ä»¥$T_0$ï¼ˆå‘ç—…æˆ–æ²»ç–—æ—¥ï¼‰ä¸ºä¸­å¿ƒè¿›è¡Œ**æ—¶é—´å¯¹é½**ï¼›ç¡®ä¿æ‰€æœ‰æ¨¡æ€æ•°æ®**ä¸€ä¸€å¯¹åº”**åˆ°æ­£ç¡®çš„ç—…ä¾‹ã€‚ |
| **å»ºæ¨¡å‰å‡†å¤‡** | **ç¡®ä¿æ¨¡å‹å¯ç”¨æ€§** | æ•°æ®é›†åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰ï¼Œ**å¹³è¡¡**æ ‡ç­¾ï¼ˆå¦‚$CAL$ä¸é$CAL$ï¼‰åˆ†å¸ƒã€‚ |

æ•°æ®å‡†å¤‡å·¥ä½œé‡å·¨å¤§ï¼Œä½†é«˜è´¨é‡çš„æ•°æ®èƒ½è®©æ¨¡å‹äº‹åŠåŠŸå€ã€‚æ‚¨ç›®å‰æ˜¯å¦å·²ç»æœ‰åŸå§‹æ•°æ®ï¼Œæˆ–è€…æ­£åœ¨è€ƒè™‘ä»å“ªä¸ªåŒ»ç–—ä¸­å¿ƒè·å–æ•°æ®ï¼Ÿ
